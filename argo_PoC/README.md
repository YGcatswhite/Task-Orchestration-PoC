# Argo

![diagram](https://argoproj.github.io/argo-workflows/assets/diagram.png)

需要一个K8S集群进行kubectl配置

快速启动命令：

```shell
kubectl create ns argo
kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml
# 打开端口转发，来访问UI
kubectl -n argo port-forward deployment/argo-server 2746:2746
# 提交示例工作流
argo submit -n argo --watch https://raw.githubusercontent.com/argoproj/argo-workflows/master/examples/hello-world.yaml
# 列出工作流
argo list -n argo
# 查看工作流运行的详细信息
argo get -n argo @latest
# 查看运行日志
argo logs -n argo @latest
```

Argo被实现为K8S CRD（自定义资源定义），Argo工作流可以使用K8S进行管理和本地继承

## CTL

```shell
argo submit hello-world.yaml    # submit a workflow spec to Kubernetes
argo list                       # list current workflows
argo get hello-world-xxx        # get info about a specific workflow
argo logs hello-world-xxx       # print the logs from a workflow
argo delete hello-world-xxx     # delete workflow
# 可以直接使用kubectl Argo CLI 运行工作流规范，但提供语法检查、更好的输出并且需要更少的输入
kubectl create -f hello-world.yaml
kubectl get wf
kubectl get wf hello-world-xxx
kubectl get po --selector=workflows.argoproj.io/workflow=hello-world-xxx --show-all  # similar to argo
kubectl logs hello-world-xxx-yyy -c main
kubectl delete wf hello-world-xxx
```

示例（Hello world）：

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow                  # new type of k8s spec
metadata:
  generateName: hello-world-    # name of the workflow spec
spec:
  entrypoint: whalesay          # invoke the whalesay template
  templates:
    - name: whalesay              # name of the template
      container:
        image: docker/whalesay
        command: [ cowsay ]
        args: [ "hello world" ]
        resources: # limit the resources
          limits:
            memory: 32Mi
            cpu: 100m
```

参数：{{inputs.parameters.message}}，此外argo CLI 提供了一个命令来加载 YAML 或 JSON 格式的参数文件如：argo submit arguments-parameters.yaml --parameter-file params.yaml，可以通过--entrypoint whalesay-caps而不更改默认入口点，在spec.arguments.parameters定义的参数是全局的，可以用{{workflow.parameters.parameter_name}}进行调用

根据double bash还是single bash（'-'）来判定是在上一步之后完成还是完成到下一步

## DAG

**支持并行运行**

```yaml
# eg
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dag-diamond-
spec:
  entrypoint: diamond
  templates:
  - name: echo
    inputs:
      parameters:
      - name: message
    container:
      image: alpine:3.7
      command: [echo, "{{inputs.parameters.message}}"]
  - name: diamond
    dag:
      tasks:
      - name: A
        template: echo
        arguments:
          parameters: [{name: message, value: A}]
      - name: B
        dependencies: [A]
        template: echo
        arguments:
          parameters: [{name: message, value: B}]
      - name: C
        dependencies: [A]
        template: echo
        arguments:
          parameters: [{name: message, value: C}]
      - name: D
        dependencies: [B, C]
        template: echo
        arguments:
          parameters: [{name: message, value: D}]
```

在运行工作流的时候，具有生成和使用artifact的步骤很正常，通常一个步骤的输出Atifact可以用作后续步骤的输入artifact，在这之前要配置artifact存储库，对于输入和输出的存储形式如下：

| Name        | Inputs | Outputs | Usage (Feb 2020) |
| :---------- | :----- | :------ | :--------------- |
| Artifactory | Yes    | Yes     | 11%              |
| GCS         | Yes    | Yes     | -                |
| Git         | Yes    | No      | -                |
| HDFS        | Yes    | Yes     | 3%               |
| HTTP        | Yes    | No      | 2%               |
| OSS         | Yes    | Yes     | -                |
| Raw         | Yes    | No      | 5%               |
| S3          | Yes    | Yes     | 86%              |

使用工件artifact是如下：

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: artifact-passing-
spec:
  entrypoint: artifact-example
  templates:
  - name: artifact-example
    steps:
    - - name: generate-artifact
        template: whalesay
    - - name: consume-artifact
        template: print-message
        arguments:
          artifacts:
          # bind message to the hello-art artifact
          # generated by the generate-artifact step
          - name: message
            from: "{{steps.generate-artifact.outputs.artifacts.hello-art}}"

  - name: whalesay
    container:
      image: docker/whalesay:latest
      command: [sh, -c]
      args: ["cowsay hello world | tee /tmp/hello_world.txt"]
    outputs:
      artifacts:
      # generate hello-art artifact from /tmp/hello_world.txt
      # artifacts can be directories as well as files
      - name: hello-art
        path: /tmp/hello_world.txt

  - name: print-message
    inputs:
      artifacts:
      # unpack the message input artifact
      # and put it at /tmp/message
      - name: message
        path: /tmp/message
    container:
      image: alpine:latest
      command: [sh, -c]
      args: ["cat /tmp/message"]
```

secret语法和K8S的语法一致（一个包含少量敏感数据（例如密码、令牌或密钥）的对象。此类信息可能会以其他方式放入 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/)规范或 [容器映像](https://kubernetes.io/docs/reference/glossary/?all=true#term-image)中。使用 Secret 意味着您不需要在应用程序代码中包含机密数据。）

输出参数：输出参数提供了一种通用的机制，可以将步骤的结果用作参数而不是artifact，这允许使用任何类型的步骤结果，而不是一个script，用于条件测试、循环和参数，除了将script输出参数result的值设置为生成文件而不是stdout。DAG 模板使用 tasks 前缀来引用另一个任务，例如`{{tasks.generate-parameter.outputs.parameters.hello-param}}`.

使用withItems去做循环执行，也可以动态生成参数去执行

条件语句：如果参数值包含引号，则可能会使 govaluate 表达式无效。要处理带引号的参数，请在条件中嵌入[expr](https://github.com/antonmedv/expr)表达式。使用when即可完成条件跳转

**支持失败或错误重试**：retryStrategy——limit、retryPolicy、backoff（指数回退）、affinity

递归：只需要将tamplate弄成自身即可

退出处理程序：退出处理程序的常见用例是工作流程运行后清理、发送工作流状态通知、将通过或者失败状态发布到webhook结果、重新提交或提交另一个工作流程——onExit: exit-handler

超时：限制工作流经过某个节点的时间可以设置变量activeDeadlineSeconds

volume：卷，Volumes are a very useful way to move large amounts of data from one step in a workflow to another. 

暂停：可以通过命令暂停工作流，也可以指定工作流程上的步骤进行暂停，可以通过手动恢复，或者使用duration限制时间

守护进程容器：Argo工作流可以启动在后台运行的容器，同时工作流本身继续执行。注意当工作流退出调用守护进程的模板范围时，守护进程将自动销毁，守护进程容器对于启动要测试或者用于测试的服务很有用。守护进程的最大优势在于他们的存在可以跨多个步骤甚至整个工作流程持续存在

Sidecar：是与主容器在一个pod中同时执行的，在创建多容器pod很有用

可以内置常见工件的支持

K8S资源：可以管理K8S的资源，Currently only a single resource can be managed by a resource template so either a `generateName` or `name` must be provided in the resource's meta-data.

## 用户手册

### 核心概念

#### Workflow

定义要执行的工作流，存储工作流的状态

要执行的工作流在workflow.spec字段重定义，工作流规范的核心结构是一个列表[`templates`](https://argoproj.github.io/argo-workflows/fields/#template)和一个`entrypoint`.

templates可以粗略地理解为函数，它定义要执行的指令，该entrypoint字段定义了main函数将是什么，即首先执行的template

##### template的类型

- 容器：最常见的，将调度一个container，可以在此处定义容器，container:
- 脚本：一个方便的包装器container，规范与容器相同，但添加了source，允许就地定义脚本的字段，该脚本将保存到文件中并执行，脚本的结果会根据调用方式自动导出到Argo变量中，script:
- 资源：直接对集群资源执行操作，它可以用于获取、创建、应用、删除、替换或修补集群上的资源，resource:
- 暂停：暂停模板将暂停执行一段时间或直到手动恢复。可以从 CLI（使用`argo resume`）、API 端点或 UI 恢复暂停模板。其中有duration参数，suspend:
- 步骤：步骤模板允许在一系列步骤中定义任务。这个模板的结构是列表的列表。外部列表将按照顺序运行，内部列表将并行运行，如果要串行运行内部列表，请使用同步功能，可以设置多个选项来控制执行，例如使用when。
- dag：dag 模板允许您将任务定义为依赖关系图。在 DAG 中，您列出所有任务并设置在特定任务开始之前必须完成哪些其他任务。没有任何依赖关系的任务将立即运行。dag: tasks:

### 自定义资源类型

#### workflow模板

workerflow模板是存在于定义在集群中的workflow，这允许创建一个常用的模板库，并通过直接提交它们

辨析template和WorkflowTemplate：

- 一个template是在Workflow里的一个任务，当你定义一个workflow时，你必须定义至少一个template
- workflowtemplate是在集群中存在的一个workflow，

##### Spec

所有字段都必须定义在workflowspec里，除了priority之外

出了arguments和templates字段都不能被定义

##### `workflowMetadata`

使用`workflowMetadata`添加注解和标签（labels）

##### 使用参数

- 使用全局参数时，可以在workflow中实例化全局变量，然后直接在workflowtemplate中进行饮用即可
- 使用本地参数时，本地参数的值比现在workflowtemplate中

##### 引用其它`WorkflowTemplates`

可以使用templateRef来引用workflowtemplate，注意在模板中不能创建模板

同时可以使用workflowTemplateRef创建workflow

#### Cluster Workflow Templates

是集群视角的workflowtemplate，workflowtemplate可以使用clusterScope: true开启

类型（kind）定义为ClusterWorkflowTemplate

引用其他的clusterworkflowtemplate可以使用clusterScope: true开启

#### Cron Workflows

Cron Workflows是按照时间表运行的工作流，它们意在轻松转换并模仿与K8S相同的CronJob。本质上，`CronWorkflow`= `Workflow`+ 一些特定的 cron 选项。

CronWorkflow的选项如下：

| 选项名称                     | 默认值       | 描述                                                         |
| ---------------------------- | ------------ | :----------------------------------------------------------- |
| `schedule`                   | 无，必须提供 | `Workflow`将运行的时间表。例如`5 4 * * *`                    |
| `timezone`                   | 机器时区     | 将根据 IANA 时区标准运行工作流的时区，例如`America/Los_Angeles` |
| `suspend`                    | `false`      | 如果`true`工作流调度不会发生。可以从 CLI、GitOps 或直接设置  |
| `concurrencyPolicy`          | `Allow`      | 确定`Workflows`在同时安排多个时要做什么的策略。可用选项：：`Allow`允许所有，`Replace`：在安排新的之前删除所有旧的，`Forbid`：当有旧的时不允许任何新的 |
| `startingDeadlineSeconds`    | `0`          | 上次成功运行后的秒数，在此期间`Workflow`将运行未命中         |
| `successfulJobsHistoryLimit` | `3`          | `Workflows`一次持久化的成功次数                              |
| `failedJobsHistoryLimit`     | `1`          | `Workflows`一次持久化的失败次数                              |

如果workflow-controller崩溃，可以设置一些选项来确保CronWorkflows在控制器关闭时已安排好的仍可以之后再运行

### 模板类型

HTTP模板是一种可以执行HTTP请求的模板，直接用http即可

#### 容器集模板

容器集模板类似于普通容器或脚本模板，但允许你指定多个容器在单个pod中运行；因为在一个pod中有多个容器，所以它们将被安排在同一个主机上，可以使用空闲快速的空目录卷而不是持久卷生命在步骤之间的共享数据

一个容器集实际上启动了所有的容器，而Emissary仅仅在它所以来的容器完成后才启动主容器进程，这意味着容器即使没有做任何有用的工作，它仍然在消耗资源，并且您仍然需要为它们提公共资源

#### 数据源和转换

data：模板为用户经常获取和转换数据作为工作流程的一部分提供了一系列支持，定义source数据源，并在tracformation里定义map或filter表达式

#### 内联模板

你可以在dag和steps中内联其它模板

### 工件Artifacts

#### workflow的输入

使用参数作为输入：

```yaml
# 在workflow里的参数定义
arguments:
  parameters:
  - name: workflow-param-1
# 在模板里的局部参数定义
inputs:
  parameters:
  - name: template-param-1
# 在DAG模板里使用arguments
dag:
  tasks:
  - name: step-A
    template: step-template-A
    arguments:
      parameters:
      - name: template-param-1
        value: abcd
```

使用前一步的输出作为输入：

使用from或者value

#### Key-Only工件

是输入输出工件，仅指定秘钥，省略存储桶机密等。当省略这些时，将使用工件存储库中的存储桶和机密secret

#### 工件存储库引用

可以通过配置可由任何工作流访问的存储库来减少模板中的重复。这也可以从您的模板中删除敏感信息。

#### 条件工件和参数

条件工件和参数功能可以根据表达式分配步骤/DAG 级别的工件或参数。`fromExpression: ...`这在 Step/DAG level output artifact 和`expression: ...` step/DAG level output parameter下引入了一个新字段。两者都使用 [expr](https://github.com/antonmedv/expr/blob/master/docs/Language-Definition.md)语法。

条件参数也要使用表达式

### 特征

#### workflow变量

变量要使用花括号括起来，模板标签的种类有简单地默认值和表达式expression

表达式语法

list：[1, 2]

过滤列表：filter([1, 2], { # > 1})

映射列表：map([1, 2], { # * 2 })

强转为Int值：asInt(inputs.parameters['my-int-param'])

强转为float值：asFloat(inputs.parameters['my-float-param'])

强转为string：string(1)

转换为Json串：toJson([1, 2])

从Json串中解析数据：jsonpath(inputs.parameters.json, '$.some.path')

还可以使用Sprig function

可以记录一系列模板

#### Lifecycle-Hook

一个Lifecycle-Hook是基于条件表达式触发动作的，它在工作流级别或模板级别进行配置，例如分别作为workflow.status或steps.status的函数，一个LifecycleHook在执行期间执行并执行一次

Lifecycle-Hook函数类似于带有条件表达式的退出处理程序

支持的情况：退出处理程序的变量：workflow.status`和`workflow.failures、template、templateRef、arguments

不支持的情况：outputs不可用，因为`LifecycleHook`在执行期间执行，并且`outputs`在步骤完成之前不会生成。

#### *同步

同步使用户能够限制工作流中某些工作流或模板的并行执行，而不必限制其他工作流，用户可以在其中创建多个同步配置，这些配置可以从工作流或工作流中的模板引用。或者用户可以配置互斥锁来防止使用相同互斥锁同时执行模板或工作流

如果工作流具有相同的同步引用，则工作流级同步会限制工作流的并行执行，在给定时间也只会执行一个工作流实例

#### Step级别的记忆

工作流通常具有计算成本高的输出。此功能通过记忆先前运行的步骤来降低成本和工作流执行时间，将模板的输出存储到具有可变键的指定缓存中

目前缓存只能使用configMap执行，这使得你可以轻松地通过k8S API来手动操作缓存条目，无需通过Argo进行。

记忆实在模板级别设置的，必须制定一个键，可以是静态字符串，但更多时候取决于输入，必须指定配置映射缓存的名称

#### 增强依赖逻辑

在DAG模板中指定依赖项的唯一方法是使用denpendencies字段并指定当前任务所以来的其它任务的列表。此语法具有限制性，因为它不允许用户指定要依赖的任务结果

为了解决这个问题，存在一个名为denpends的新字段，允许用户制定相关让你无，它们的状态以及任何复杂的布尔逻辑该字段是一个string字段，其语法类似于表达式。操作数具有form

| 任务结果     | 描述                           | 意义                              |
| ------------ | :----------------------------- | :-------------------------------- |
| `.Succeeded` | 任务成功                       | 任务完成，没有错误                |
| `.Failed`    | 任务失败                       | 任务以非 0 退出代码退出           |
| `.Errored`   | 任务错误                       | 任务有一个非 0 退出代码以外的错误 |
| `.Skipped`   | 任务跳过                       | 任务被跳过                        |
| `.Omitted`   | 任务省略                       | 任务被省略                        |
| `.Daemoned`  | 任务是守护进程并且不是待处理的 |                                   |

### Pattrens

#### 空目录

在默认情况下，Docker和PNS工作流执行器可以从基础层获取工件，但是K8S执行器不行，如果你使用安全上下文运行工作流Pod，则不太可能从基础层获得输出工件参数

#### Cron回填

工作流模式的工作流涉及一个父工作流触发一个或多个子工作流，管理它们并对它们的结构采取行动。

可以使用workflowTemplateRef内联触发工作流：

1. 将工作流程定义为workflowtemplate、

#### 事件

为了支持外部的webhook，我们使用这个端点/api/v1/events/{namespace}/{discriminator}，发送给它的事件可以是任何JSON数据，有些事件可以提交工作流模板或者集群工作流模板

想要向端点发送事件的客户端需要一个访问令牌，只能提交到你的访问令牌有权访问的工作流模板中

### 最佳实践

#### 工作流Pod安全上下文

默认情况下，所有工作流Pod都以root身份运行。Docker执行器甚至需要`privileged: true`，对于其他工作流执行器，可以通过为工作流Pod配置安全上下文来更加安全地运行工作流Pod。如果有Pod安全策略，这是必要的因为可能会无法使用Docker执行程序

#### 容忍Pod删除

在K8S中，Pod很牛，可以随时删除，手动删除`kubectl delete pod`，在节点耗尽期间或者出于其它原因。这可能非常不方便，工作流程就会出错出于无法控制的原因。

#### 大规模运行

Argo Workflows每天能够运行1000个工作流，每个工作流有10000个节点。但是你需要做一些工作来实现这一点，必须至少运行3.1才能使多个建议生效

在安装Argo工作流之前测试你的集群，你需要一个大型集群以及一个大型K8S主服务器。用户经常会遇到需要针对规模进行配置的K8S问题。