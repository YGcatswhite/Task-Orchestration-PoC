# Argo

![diagram](https://argoproj.github.io/argo-workflows/assets/diagram.png)

需要一个K8S集群进行kubectl配置

快速启动命令：

```shell
kubectl create ns argo
kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml
# 打开端口转发，来访问UI
kubectl -n argo port-forward deployment/argo-server 2746:2746
# 提交示例工作流
argo submit -n argo --watch https://raw.githubusercontent.com/argoproj/argo-workflows/master/examples/hello-world.yaml
# 列出工作流
argo list -n argo
# 查看工作流运行的详细信息
argo get -n argo @latest
# 查看运行日志
argo logs -n argo @latest
```

Argo被实现为K8S CRD（自定义资源定义），Argo工作流可以使用K8S进行管理和本地继承

## CTL

```shell
argo submit hello-world.yaml    # submit a workflow spec to Kubernetes
argo list                       # list current workflows
argo get hello-world-xxx        # get info about a specific workflow
argo logs hello-world-xxx       # print the logs from a workflow
argo delete hello-world-xxx     # delete workflow
# 可以直接使用kubectl Argo CLI 运行工作流规范，但提供语法检查、更好的输出并且需要更少的输入
kubectl create -f hello-world.yaml
kubectl get wf
kubectl get wf hello-world-xxx
kubectl get po --selector=workflows.argoproj.io/workflow=hello-world-xxx --show-all  # similar to argo
kubectl logs hello-world-xxx-yyy -c main
kubectl delete wf hello-world-xxx
```

示例（Hello world）：

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow                  # new type of k8s spec
metadata:
  generateName: hello-world-    # name of the workflow spec
spec:
  entrypoint: whalesay          # invoke the whalesay template
  templates:
    - name: whalesay              # name of the template
      container:
        image: docker/whalesay
        command: [ cowsay ]
        args: [ "hello world" ]
        resources: # limit the resources
          limits:
            memory: 32Mi
            cpu: 100m
```

参数：{{inputs.parameters.message}}，此外argo CLI 提供了一个命令来加载 YAML 或 JSON 格式的参数文件如：argo submit arguments-parameters.yaml --parameter-file params.yaml，可以通过--entrypoint whalesay-caps而不更改默认入口点，在spec.arguments.parameters定义的参数是全局的，可以用{{workflow.parameters.parameter_name}}进行调用

根据double bash还是single bash（'-'）来判定是在上一步之后完成还是完成到下一步

## DAG

**支持并行运行**

```yaml
# eg
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dag-diamond-
spec:
  entrypoint: diamond
  templates:
  - name: echo
    inputs:
      parameters:
      - name: message
    container:
      image: alpine:3.7
      command: [echo, "{{inputs.parameters.message}}"]
  - name: diamond
    dag:
      tasks:
      - name: A
        template: echo
        arguments:
          parameters: [{name: message, value: A}]
      - name: B
        dependencies: [A]
        template: echo
        arguments:
          parameters: [{name: message, value: B}]
      - name: C
        dependencies: [A]
        template: echo
        arguments:
          parameters: [{name: message, value: C}]
      - name: D
        dependencies: [B, C]
        template: echo
        arguments:
          parameters: [{name: message, value: D}]
```

在运行工作流的时候，具有生成和使用artifact的步骤很正常，通常一个步骤的输出Atifact可以用作后续步骤的输入artifact，在这之前要配置artifact存储库，对于输入和输出的存储形式如下：

| Name        | Inputs | Outputs | Usage (Feb 2020) |
| :---------- | :----- | :------ | :--------------- |
| Artifactory | Yes    | Yes     | 11%              |
| GCS         | Yes    | Yes     | -                |
| Git         | Yes    | No      | -                |
| HDFS        | Yes    | Yes     | 3%               |
| HTTP        | Yes    | No      | 2%               |
| OSS         | Yes    | Yes     | -                |
| Raw         | Yes    | No      | 5%               |
| S3          | Yes    | Yes     | 86%              |

使用工件artifact是如下：

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: artifact-passing-
spec:
  entrypoint: artifact-example
  templates:
  - name: artifact-example
    steps:
    - - name: generate-artifact
        template: whalesay
    - - name: consume-artifact
        template: print-message
        arguments:
          artifacts:
          # bind message to the hello-art artifact
          # generated by the generate-artifact step
          - name: message
            from: "{{steps.generate-artifact.outputs.artifacts.hello-art}}"

  - name: whalesay
    container:
      image: docker/whalesay:latest
      command: [sh, -c]
      args: ["cowsay hello world | tee /tmp/hello_world.txt"]
    outputs:
      artifacts:
      # generate hello-art artifact from /tmp/hello_world.txt
      # artifacts can be directories as well as files
      - name: hello-art
        path: /tmp/hello_world.txt

  - name: print-message
    inputs:
      artifacts:
      # unpack the message input artifact
      # and put it at /tmp/message
      - name: message
        path: /tmp/message
    container:
      image: alpine:latest
      command: [sh, -c]
      args: ["cat /tmp/message"]
```

secret语法和K8S的语法一致（一个包含少量敏感数据（例如密码、令牌或密钥）的对象。此类信息可能会以其他方式放入 [Pod](https://kubernetes.io/docs/concepts/workloads/pods/)规范或 [容器映像](https://kubernetes.io/docs/reference/glossary/?all=true#term-image)中。使用 Secret 意味着您不需要在应用程序代码中包含机密数据。）

输出参数：输出参数提供了一种通用的机制，可以将步骤的结果用作参数而不是artifact，这允许使用任何类型的步骤结果，而不是一个script，用于条件测试、循环和参数，除了将script输出参数result的值设置为生成文件而不是stdout。DAG 模板使用 tasks 前缀来引用另一个任务，例如`{{tasks.generate-parameter.outputs.parameters.hello-param}}`.

使用withItems去做循环执行，也可以动态生成参数去执行

条件语句：如果参数值包含引号，则可能会使 govaluate 表达式无效。要处理带引号的参数，请在条件中嵌入[expr](https://github.com/antonmedv/expr)表达式。使用when即可完成条件跳转

**支持失败或错误重试**：retryStrategy——limit、retryPolicy、backoff（指数回退）、affinity

递归：只需要将tamplate弄成自身即可

退出处理程序：退出处理程序的常见用例是工作流程运行后清理、发送工作流状态通知、将通过或者失败状态发布到webhook结果、重新提交或提交另一个工作流程——onExit: exit-handler

超时：限制工作流经过某个节点的时间可以设置变量activeDeadlineSeconds

volume：卷，Volumes are a very useful way to move large amounts of data from one step in a workflow to another. 

暂停：可以通过命令暂停工作流，也可以指定工作流程上的步骤进行暂停，可以通过手动恢复，或者使用duration限制时间

守护进程容器：Argo工作流可以启动在后台运行的容器，同时工作流本身继续执行。注意当工作流退出调用守护进程的模板范围时，守护进程将自动销毁，守护进程容器对于启动要测试或者用于测试的服务很有用。守护进程的最大优势在于他们的存在可以跨多个步骤甚至整个工作流程持续存在

Sidecar：是与主容器在一个pod中同时执行的，在创建多容器pod很有用

可以内置常见工件的支持

K8S资源：可以管理K8S的资源，Currently only a single resource can be managed by a resource template so either a `generateName` or `name` must be provided in the resource's meta-data.

## 用户手册

### 核心概念

#### Workflow

定义要执行的工作流，存储工作流的状态

要执行的工作流在workflow.spec字段重定义，工作流规范的核心结构是一个列表[`templates`](https://argoproj.github.io/argo-workflows/fields/#template)和一个`entrypoint`.

templates可以粗略地理解为函数，它定义要执行的指令，该entrypoint字段定义了main函数将是什么，即首先执行的template

##### template的类型

- 容器：最常见的，将调度一个container，可以在此处定义容器，container:
- 脚本：一个方便的包装器container，规范与容器相同，但添加了source，允许就地定义脚本的字段，该脚本将保存到文件中并执行，脚本的结果会根据调用方式自动导出到Argo变量中，script:
- 资源：直接对集群资源执行操作，它可以用于获取、创建、应用、删除、替换或修补集群上的资源，resource:
- 暂停：暂停模板将暂停执行一段时间或直到手动恢复。可以从 CLI（使用`argo resume`）、API 端点或 UI 恢复暂停模板。其中有duration参数，suspend:
- 步骤：步骤模板允许在一系列步骤中定义任务。这个模板的结构是列表的列表。外部列表将按照顺序运行，内部列表将并行运行，如果要串行运行内部列表，请使用同步功能，可以设置多个选项来控制执行，例如使用when。
- dag：dag 模板允许您将任务定义为依赖关系图。在 DAG 中，您列出所有任务并设置在特定任务开始之前必须完成哪些其他任务。没有任何依赖关系的任务将立即运行。dag: tasks:

### 自定义资源类型

#### workflow模板

workerflow模板是存在于定义在集群中的workflow，这允许创建一个常用的模板库，并通过直接提交它们

辨析template和WorkflowTemplate：

- 一个template是在Workflow里的一个任务，当你定义一个workflow时，你必须定义至少一个template
- workflowtemplate是在集群中存在的一个workflow，

##### Spec

所有字段都必须定义在workflowspec里，除了priority之外

出了arguments和templates字段都不能被定义

##### `workflowMetadata`

使用`workflowMetadata`添加注解和标签（labels）

##### 使用参数

- 使用全局参数时，可以在workflow中实例化全局变量，然后直接在workflowtemplate中进行饮用即可
- 使用本地参数时，本地参数的值比现在workflowtemplate中

##### 引用其它`WorkflowTemplates`

可以使用templateRef来引用workflowtemplate，注意在模板中不能创建模板

同时可以使用workflowTemplateRef创建workflow

#### Cluster Workflow Templates

是集群视角的workflowtemplate，workflowtemplate可以使用clusterScope: true开启

类型（kind）定义为ClusterWorkflowTemplate

引用其他的clusterworkflowtemplate可以使用clusterScope: true开启

#### Cron Workflows

Cron Workflows是按照时间表运行的工作流，它们意在轻松转换并模仿与K8S相同的CronJob。本质上，`CronWorkflow`= `Workflow`+ 一些特定的 cron 选项。

CronWorkflow的选项如下：

| 选项名称                     | 默认值       | 描述                                                         |
| ---------------------------- | ------------ | :----------------------------------------------------------- |
| `schedule`                   | 无，必须提供 | `Workflow`将运行的时间表。例如`5 4 * * *`                    |
| `timezone`                   | 机器时区     | 将根据 IANA 时区标准运行工作流的时区，例如`America/Los_Angeles` |
| `suspend`                    | `false`      | 如果`true`工作流调度不会发生。可以从 CLI、GitOps 或直接设置  |
| `concurrencyPolicy`          | `Allow`      | 确定`Workflows`在同时安排多个时要做什么的策略。可用选项：：`Allow`允许所有，`Replace`：在安排新的之前删除所有旧的，`Forbid`：当有旧的时不允许任何新的 |
| `startingDeadlineSeconds`    | `0`          | 上次成功运行后的秒数，在此期间`Workflow`将运行未命中         |
| `successfulJobsHistoryLimit` | `3`          | `Workflows`一次持久化的成功次数                              |
| `failedJobsHistoryLimit`     | `1`          | `Workflows`一次持久化的失败次数                              |

如果workflow-controller崩溃，可以设置一些选项来确保CronWorkflows在控制器关闭时已安排好的仍可以之后再运行

### 模板类型

HTTP模板是一种可以执行HTTP请求的模板，直接用http即可

#### 容器集模板

容器集模板类似于普通容器或脚本模板，但允许你指定多个容器在单个pod中运行；因为在一个pod中有多个容器，所以它们将被安排在同一个主机上，可以使用空闲快速的空目录卷而不是持久卷生命在步骤之间的共享数据

一个容器集实际上启动了所有的容器，而Emissary仅仅在它所以来的容器完成后才启动主容器进程，这意味着容器即使没有做任何有用的工作，它仍然在消耗资源，并且您仍然需要为它们提公共资源

#### 数据源和转换

data：模板为用户经常获取和转换数据作为工作流程的一部分提供了一系列支持，定义source数据源，并在tracformation里定义map或filter表达式

#### 内联模板

你可以在dag和steps中内联其它模板

### 工件Artifacts

#### workflow的输入

使用参数作为输入：

```yaml
# 在workflow里的参数定义
arguments:
  parameters:
  - name: workflow-param-1
# 在模板里的局部参数定义
inputs:
  parameters:
  - name: template-param-1
# 在DAG模板里使用arguments
dag:
  tasks:
  - name: step-A
    template: step-template-A
    arguments:
      parameters:
      - name: template-param-1
        value: abcd
```

使用前一步的输出作为输入：

使用from或者value

#### Key-Only工件

是输入输出工件，仅指定秘钥，省略存储桶机密等。当省略这些时，将使用工件存储库中的存储桶和机密secret

#### 工件存储库引用

可以通过配置可由任何工作流访问的存储库来减少模板中的重复。这也可以从您的模板中删除敏感信息。

#### 条件工件和参数

条件工件和参数功能可以根据表达式分配步骤/DAG 级别的工件或参数。`fromExpression: ...`这在 Step/DAG level output artifact 和`expression: ...` step/DAG level output parameter下引入了一个新字段。两者都使用 [expr](https://github.com/antonmedv/expr/blob/master/docs/Language-Definition.md)语法。

条件参数也要使用表达式

### 特征

#### workflow变量

变量要使用花括号括起来，模板标签的种类有简单地默认值和表达式expression

表达式语法

list：[1, 2]

过滤列表：filter([1, 2], { # > 1})

映射列表：map([1, 2], { # * 2 })